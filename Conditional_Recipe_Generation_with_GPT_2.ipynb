{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Conditional Recipe Generation with GPT-2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2164d06d725a4850921e999ab673f183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_888afac251ae44d8961a55ba57c43774",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_28a66d21e65142b7872dfcaef268769f",
              "IPY_MODEL_9f1017edc28b41fda56c7774ed734a5c"
            ]
          }
        },
        "888afac251ae44d8961a55ba57c43774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28a66d21e65142b7872dfcaef268769f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_92cb586244a746b1a4c1e849a5bfe3de",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1713123,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1713123,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c5aa1782c104815b4b7e008c16b19a2"
          }
        },
        "9f1017edc28b41fda56c7774ed734a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b423a7a3199432e9f74aa065dacc1c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.71M/1.71M [00:00&lt;00:00, 2.24MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6523c634db0467d8a7c12c54b21a509"
          }
        },
        "92cb586244a746b1a4c1e849a5bfe3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c5aa1782c104815b4b7e008c16b19a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b423a7a3199432e9f74aa065dacc1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6523c634db0467d8a7c12c54b21a509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44e95ed4f8644977bdbbaca6e04830a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a3282d7ac15b489aae0f38e63b5e9410",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1cf77729c55c416798ed956a402bb8cb",
              "IPY_MODEL_aee88f42eb5548728981a8b0e0babecd"
            ]
          }
        },
        "a3282d7ac15b489aae0f38e63b5e9410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cf77729c55c416798ed956a402bb8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_99d189c3d71147fdbc24e120de072dec",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1270925,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1270925,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4774ad096f54965a76e429c844b6405"
          }
        },
        "aee88f42eb5548728981a8b0e0babecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5aa303f44fbf4517877c3db3f65a81c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.27M/1.27M [00:01&lt;00:00, 713kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f06682b62bfb41fcad588798fed83d2a"
          }
        },
        "99d189c3d71147fdbc24e120de072dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4774ad096f54965a76e429c844b6405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5aa303f44fbf4517877c3db3f65a81c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f06682b62bfb41fcad588798fed83d2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4fc4e4aaea34224ab5fae0515624a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bcb8faf85c38485895a6abd79446c6fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dfabbf8928fd43619ea5009e4b1f9469",
              "IPY_MODEL_6bd37601cf7a4e1f95acc4544c71ef39"
            ]
          }
        },
        "bcb8faf85c38485895a6abd79446c6fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfabbf8928fd43619ea5009e4b1f9469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9a325986b213409e9559029d7ffea0a1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 608,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 608,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_341bd88d699846ae83d1866d16b72789"
          }
        },
        "6bd37601cf7a4e1f95acc4544c71ef39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d961122e8f1440e1a772acf2523f60a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 608/608 [00:00&lt;00:00, 1.48kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b117a0068a9741b3bd2f0f2ae10ac607"
          }
        },
        "9a325986b213409e9559029d7ffea0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "341bd88d699846ae83d1866d16b72789": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d961122e8f1440e1a772acf2523f60a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b117a0068a9741b3bd2f0f2ae10ac607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c7e9e9c90e0419c8bb4c29466d4dc9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4d19287757f54f9d8b89d310e4811234",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ddc53610abe4ce9a8eb90f51798bb08",
              "IPY_MODEL_8a385136c880484895efb18a4f132eed"
            ]
          }
        },
        "4d19287757f54f9d8b89d310e4811234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ddc53610abe4ce9a8eb90f51798bb08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a188e357095b451fb552bb67fc6b688b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 551290714,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 551290714,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3bb83939b1f4446a822fabe69a9fecd"
          }
        },
        "8a385136c880484895efb18a4f132eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3cf800e0e354483fa05734d4cc7fb610",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 551M/551M [00:11&lt;00:00, 47.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76d02fe31b124ce1b0dcb8825fb06039"
          }
        },
        "a188e357095b451fb552bb67fc6b688b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3bb83939b1f4446a822fabe69a9fecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3cf800e0e354483fa05734d4cc7fb610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76d02fe31b124ce1b0dcb8825fb06039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwRhz144Fknp"
      },
      "source": [
        "Related article: https://www.ivanlai.project-ds.net/post/conditional-text-generation-by-fine-tuning-gpt-2\n",
        "\n",
        "Preprocessing code in [this](https://github.com/ivanlai/Conditional_Text_Generation) Github repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSWYe3LMSP-b"
      },
      "source": [
        "### Install and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xk9lb9GmZuS",
        "outputId": "ab552b2e-7e0a-4dd2-8505-d86e0a37d8e7"
      },
      "source": [
        "%%time\n",
        "%%capture\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 43.2 ms, sys: 22.4 ms, total: 65.6 ms\n",
            "Wall time: 6.27 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL6-XP7zzH7h",
        "outputId": "b06b9791-1f36-47a9-e161-488d29ae1387"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import zipfile\n",
        "import random\n",
        "import time\n",
        "import csv\n",
        "import datetime\n",
        "from itertools import compress\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForPreTraining, \\\n",
        "                         AdamW, get_linear_schedule_with_warmup, \\\n",
        "                         TrainingArguments, BeamScorer, Trainer, \\\n",
        "                         GPT2Tokenizer, GPT2LMHeadModel, AdamW\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, \\\n",
        "                             RandomSampler, SequentialSampler\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('You got a GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "\n",
        "# pd.set_option('display.max_colwidth', None)\n",
        "# pd.set_option('display.max_rows', None)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You got a GPU: Tesla V100-SXM2-16GB\n",
            "PyTorch version: 1.9.0+cu102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAskWhfbrzlv",
        "outputId": "6995ae60-6211-4ee5-f577-bb70e652f225"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZDy9RClRiQ3"
      },
      "source": [
        "### Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QILzrXuoRhaF"
      },
      "source": [
        "DEBUG           = False\n",
        "\n",
        "INPUT_DIR       = 'articles'\n",
        "\n",
        "USE_APEX        = True\n",
        "APEX_OPT_LEVEL  = 'O1'\n",
        "\n",
        "MODEL           = 'sberbank-ai/rugpt3small_based_on_gpt2' #{'gpt2', gpt2, gpt2-medium, gpt2-large, gpt2-xl}\n",
        "\n",
        "UNFREEZE_LAST_N = 6 #The last N layers to unfreeze for training\n",
        "\n",
        "SPECIAL_TOKENS  = { \"bos_token\": \"<|BOS|>\",\n",
        "                    \"eos_token\": \"<|EOS|>\",\n",
        "                    \"unk_token\": \"<|UNK|>\",                    \n",
        "                    \"pad_token\": \"<|PAD|>\",\n",
        "                    \"sep_token\": \"<|SEP|>\"}\n",
        "                    \n",
        "MAXLEN          = 768  #{768, 1024, 1280, 1600}\n",
        "\n",
        "TRAIN_SIZE      = 0.8\n",
        "\n",
        "if USE_APEX:\n",
        "    TRAIN_BATCHSIZE = 4\n",
        "    BATCH_UPDATE    = 24\n",
        "else:\n",
        "    TRAIN_BATCHSIZE = 4\n",
        "    BATCH_UPDATE    = 16\n",
        "\n",
        "EPOCHS          = 15\n",
        "LR              = 5e-4\n",
        "EPS             = 1e-8\n",
        "WARMUP_STEPS    = 1e2\n",
        "\n",
        "SEED            = 2021"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "740ZIyZXRbWe"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZMJko4Vxc-T"
      },
      "source": [
        "## Preprocessing df and create dictionary for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwx5CIuIuSUE"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/alco.xls')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9kFcD9IvQo9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "3ddeefc7-8df7-4812-8788-17c7a6114dd8"
      },
      "source": [
        "df['ingridients'] = df['ingridients'].str.lower()\n",
        "df['ingridients'] = df['ingridients'].str.split(' ,')\n",
        "df.drop(['weight'], axis = 1, inplace = True)\n",
        "df.drop(df.index[df['recipe'].str.find('настаивай') != -1], axis = 0, inplace = True)\n",
        "\n",
        "df = df.reset_index()\n",
        "df =  df.reindex(columns=['index', 'name', 'recipe', 'ingridients'])\n",
        "df.drop('index', axis = 1, inplace=True)\n",
        "df = df.reset_index()\n",
        "df"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>name</th>\n",
              "      <th>recipe</th>\n",
              "      <th>ingridients</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Манхэттен</td>\n",
              "      <td>Налей в стакан для смешивания красный вермут 2...</td>\n",
              "      <td>[бурбон, красный вермут, ангостура биттер, кок...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Секс на пляже</td>\n",
              "      <td>Наполни слинг кубиками льда доверху,Налей в ше...</td>\n",
              "      <td>[водка, персиковый ликер, клюквенный сок, анан...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Космополитен</td>\n",
              "      <td>Налей в шейкер лаймовый сок 10 мл, клюквенный ...</td>\n",
              "      <td>[цитрусовая водка, трипл сек, клюквенный сок, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Б-52</td>\n",
              "      <td>Налей в стопку кофейный ликер 15 мл,Используя ...</td>\n",
              "      <td>[кофейный ликер, айриш крим, трипл сек ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Голубая лагуна</td>\n",
              "      <td>Наполни харрикейн кубиками льда доверху,Налей ...</td>\n",
              "      <td>[водка, ликер блю кюрасао, спрайт, ананас, лед...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1145</th>\n",
              "      <td>1145</td>\n",
              "      <td>Карибский бриз</td>\n",
              "      <td>Наполни хайбол кубиками льда доверху,Налей гре...</td>\n",
              "      <td>[грейпфрутовая водка, домашняя ванильная водка...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1146</th>\n",
              "      <td>1146</td>\n",
              "      <td>Текила санрайз</td>\n",
              "      <td>Наполни хайбол кубиками льда доверху,Налей гре...</td>\n",
              "      <td>[серебряная текила, гренадин, апельсиновый сок...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1147</th>\n",
              "      <td>1147</td>\n",
              "      <td>Мохито</td>\n",
              "      <td>Положи в хайбол лайм 3 дольки и подави мадлеро...</td>\n",
              "      <td>[белый ром, сахарный сироп, содовая, лайм, мят...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1148</th>\n",
              "      <td>1148</td>\n",
              "      <td>Белый русский</td>\n",
              "      <td>Наполни рокс кубиками льда доверху,Налей в бок...</td>\n",
              "      <td>[водка, кофейный ликер, нежирные сливки, лед в...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1149</th>\n",
              "      <td>1149</td>\n",
              "      <td>Негрони</td>\n",
              "      <td>Наполни рокс кубиками льда доверху,Налей в бок...</td>\n",
              "      <td>[лондонский сухой джин, красный вермут, красны...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1150 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ...                                        ingridients\n",
              "0         0  ...  [бурбон, красный вермут, ангостура биттер, кок...\n",
              "1         1  ...  [водка, персиковый ликер, клюквенный сок, анан...\n",
              "2         2  ...  [цитрусовая водка, трипл сек, клюквенный сок, ...\n",
              "3         3  ...           [кофейный ликер, айриш крим, трипл сек ]\n",
              "4         4  ...  [водка, ликер блю кюрасао, спрайт, ананас, лед...\n",
              "...     ...  ...                                                ...\n",
              "1145   1145  ...  [грейпфрутовая водка, домашняя ванильная водка...\n",
              "1146   1146  ...  [серебряная текила, гренадин, апельсиновый сок...\n",
              "1147   1147  ...  [белый ром, сахарный сироп, содовая, лайм, мят...\n",
              "1148   1148  ...  [водка, кофейный ликер, нежирные сливки, лед в...\n",
              "1149   1149  ...  [лондонский сухой джин, красный вермут, красны...\n",
              "\n",
              "[1150 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "EWyy4j6Sx7K2",
        "outputId": "efbe7862-55f5-4b61-d7a0-88d4545ea16e"
      },
      "source": [
        "df['recipe'] = df['recipe'].str.replace(r',+(?=[А-Я])', '. ')\n",
        "df['recipe'] = df['recipe'].str.replace('1 к. ', '1 коктейльную ')\n",
        "df['recipe'] = df['recipe'].str.replace(' к. ', ' коктейльных ')\n",
        "df['recipe'] = df['recipe'].str.replace('без газа', '')\n",
        "df['recipe'] = df['recipe'].str.replace('-', '')\n",
        "df['recipe'] = df['recipe'].str.replace('\\xa0', '')\n",
        "df['recipe'] = df['recipe'].str.replace('\\xad', '')\n",
        "\n",
        "\n",
        "\n",
        "df['ingridients'] = df['ingridients'].replace('Вода без газа', 'Вода')\n",
        "for i in range(df.shape[0]):\n",
        "  for j in range(len(df['ingridients'][i])):\n",
        "    df['ingridients'][i][j] = df['ingridients'][i][j].rstrip()\n",
        "    df['ingridients'][i][j] = df['ingridients'][i][j].replace('-', '')\n",
        "    df['ingridients'][i][j] = df['ingridients'][i][j].replace('\\xa0', '')\n",
        "    df['ingridients'][i][j] = df['ingridients'][i][j].replace('\\xad', '')\n",
        "  if 'Вода без газа' in df['ingridients'][i]:\n",
        "    item = df['ingridients'][i].index('Вода без газа')\n",
        "    df['ingridients'][i][item] = 'Вода'\n",
        "df"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>name</th>\n",
              "      <th>recipe</th>\n",
              "      <th>ingridients</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Манхэттен</td>\n",
              "      <td>Налей в стакан для смешивания красный вермут 2...</td>\n",
              "      <td>[бурбон, красный вермут, ангостура биттер, кок...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Секс на пляже</td>\n",
              "      <td>Наполни слинг кубиками льда доверху. Налей в ш...</td>\n",
              "      <td>[водка, персиковый ликер, клюквенный сок, анан...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Космополитен</td>\n",
              "      <td>Налей в шейкер лаймовый сок 10 мл, клюквенный ...</td>\n",
              "      <td>[цитрусовая водка, трипл сек, клюквенный сок, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Б-52</td>\n",
              "      <td>Налей в стопку кофейный ликер 15 мл. Используя...</td>\n",
              "      <td>[кофейный ликер, айриш крим, трипл сек]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Голубая лагуна</td>\n",
              "      <td>Наполни харрикейн кубиками льда доверху. Налей...</td>\n",
              "      <td>[водка, ликер блю кюрасао, спрайт, ананас, лед...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1145</th>\n",
              "      <td>1145</td>\n",
              "      <td>Карибский бриз</td>\n",
              "      <td>Наполни хайбол кубиками льда доверху. Налей гр...</td>\n",
              "      <td>[грейпфрутовая водка, домашняя ванильная водка...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1146</th>\n",
              "      <td>1146</td>\n",
              "      <td>Текила санрайз</td>\n",
              "      <td>Наполни хайбол кубиками льда доверху. Налей гр...</td>\n",
              "      <td>[серебряная текила, гренадин, апельсиновый сок...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1147</th>\n",
              "      <td>1147</td>\n",
              "      <td>Мохито</td>\n",
              "      <td>Положи в хайбол лайм 3 дольки и подави мадлеро...</td>\n",
              "      <td>[белый ром, сахарный сироп, содовая, лайм, мят...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1148</th>\n",
              "      <td>1148</td>\n",
              "      <td>Белый русский</td>\n",
              "      <td>Наполни рокс кубиками льда доверху. Налей в бо...</td>\n",
              "      <td>[водка, кофейный ликер, нежирные сливки, лед в...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1149</th>\n",
              "      <td>1149</td>\n",
              "      <td>Негрони</td>\n",
              "      <td>Наполни рокс кубиками льда доверху. Налей в бо...</td>\n",
              "      <td>[лондонский сухой джин, красный вермут, красны...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1150 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ...                                        ingridients\n",
              "0         0  ...  [бурбон, красный вермут, ангостура биттер, кок...\n",
              "1         1  ...  [водка, персиковый ликер, клюквенный сок, анан...\n",
              "2         2  ...  [цитрусовая водка, трипл сек, клюквенный сок, ...\n",
              "3         3  ...            [кофейный ликер, айриш крим, трипл сек]\n",
              "4         4  ...  [водка, ликер блю кюрасао, спрайт, ананас, лед...\n",
              "...     ...  ...                                                ...\n",
              "1145   1145  ...  [грейпфрутовая водка, домашняя ванильная водка...\n",
              "1146   1146  ...  [серебряная текила, гренадин, апельсиновый сок...\n",
              "1147   1147  ...  [белый ром, сахарный сироп, содовая, лайм, мят...\n",
              "1148   1148  ...  [водка, кофейный ликер, нежирные сливки, лед в...\n",
              "1149   1149  ...  [лондонский сухой джин, красный вермут, красны...\n",
              "\n",
              "[1150 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGjuXCD4d1ZU"
      },
      "source": [
        "#Создание уникальных значений ингредиентов\n",
        "from pandas.core.common import flatten\n",
        "\n",
        "unqiue_ingredients = set(flatten(df.ingridients))\n",
        "unqiue_ingredients"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3yX56Aj1fdO"
      },
      "source": [
        "data = df.set_index('index').T.to_dict('list')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j0V83HbH6QF"
      },
      "source": [
        "### Datasets and loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8gp0I8JnMEE"
      },
      "source": [
        "class myDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, tokenizer, randomize=True):\n",
        "\n",
        "        title, text, keywords = [], [], []\n",
        "        for k, v in data.items():\n",
        "            title.append(v[0])\n",
        "            text.append(v[1])\n",
        "            keywords.append(v[2])\n",
        "\n",
        "        self.randomize = randomize\n",
        "        self.tokenizer = tokenizer \n",
        "        self.title     = title\n",
        "        self.text      = text\n",
        "        self.keywords  = keywords  \n",
        "\n",
        "    #---------------------------------------------#\n",
        "\n",
        "    @staticmethod\n",
        "    def join_keywords(keywords, randomize=True):\n",
        "        N = len(keywords)\n",
        "\n",
        "        #random sampling and shuffle\n",
        "        if randomize: \n",
        "            M = random.choice(range(N+1))\n",
        "            keywords = keywords[:M]\n",
        "            random.shuffle(keywords)\n",
        "\n",
        "        return ','.join(keywords)\n",
        "\n",
        "    #---------------------------------------------#\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    #---------------------------------------------#\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        keywords = self.keywords[i].copy()\n",
        "        kw = self.join_keywords(keywords, self.randomize)\n",
        "        \n",
        "        input = SPECIAL_TOKENS['bos_token'] + self.title[i] + \\\n",
        "                SPECIAL_TOKENS['sep_token'] + kw + SPECIAL_TOKENS['sep_token'] + \\\n",
        "                self.text[i] + SPECIAL_TOKENS['eos_token']\n",
        "\n",
        "        encodings_dict = self.tokenizer(input,                                   \n",
        "                                   truncation=True, \n",
        "                                   max_length=MAXLEN, \n",
        "                                   padding=\"max_length\")   \n",
        "        \n",
        "        input_ids = encodings_dict['input_ids']\n",
        "        attention_mask = encodings_dict['attention_mask']\n",
        "        \n",
        "        return {'label': torch.tensor(input_ids),\n",
        "                'input_ids': torch.tensor(input_ids), \n",
        "                'attention_mask': torch.tensor(attention_mask)}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwCXZgyrU7P5"
      },
      "source": [
        "def split_data(data, S=TRAIN_SIZE):\n",
        "    # Shuffle ids\n",
        "    ids = list(data.keys())\n",
        "    random.shuffle(ids)\n",
        "\n",
        "    # Split into training and validation sets    \n",
        "    train_size = int(S * len(data))\n",
        "\n",
        "    train_ids = ids[:train_size]\n",
        "    val_ids = ids[train_size:]\n",
        "\n",
        "    train_data = dict()\n",
        "    for id in train_ids:\n",
        "        train_data[id] = data[id]\n",
        "\n",
        "    val_data = dict()\n",
        "    for id in val_ids:\n",
        "        val_data[id] = data[id]\n",
        "\n",
        "    return train_data, val_data"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3LfEbc5j9Yo"
      },
      "source": [
        "### Loading Tokenizer, Config and Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knL24TEIX9fl"
      },
      "source": [
        "def get_tokenier(special_tokens=None):\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(MODEL) #GPT2Tokenizer\n",
        "\n",
        "    if special_tokens:\n",
        "        tokenizer.add_special_tokens(special_tokens)\n",
        "        print(\"Special tokens added\")\n",
        "    return tokenizer\n",
        "\n",
        "def get_model(tokenizer, special_tokens=None, load_model_path=None):\n",
        "\n",
        "    #GPT2LMHeadModel\n",
        "    if special_tokens:\n",
        "        config = AutoConfig.from_pretrained(MODEL, \n",
        "                                            bos_token_id=tokenizer.bos_token_id,\n",
        "                                            eos_token_id=tokenizer.eos_token_id,\n",
        "                                            sep_token_id=tokenizer.sep_token_id,\n",
        "                                            pad_token_id=tokenizer.pad_token_id,\n",
        "                                            output_hidden_states=False)\n",
        "    else: \n",
        "        config = AutoConfig.from_pretrained(MODEL,                                     \n",
        "                                            pad_token_id=tokenizer.eos_token_id,\n",
        "                                            output_hidden_states=False)    \n",
        "\n",
        "    #----------------------------------------------------------------#\n",
        "    model = AutoModelForPreTraining.from_pretrained(MODEL, config=config)\n",
        "\n",
        "    if special_tokens:\n",
        "        #Special tokens added, model needs to be resized accordingly\n",
        "        model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    if load_model_path:\n",
        "        model.load_state_dict(torch.load(load_model_path))\n",
        "\n",
        "    model.cuda()\n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2zrELuFTzEG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "2164d06d725a4850921e999ab673f183",
            "888afac251ae44d8961a55ba57c43774",
            "28a66d21e65142b7872dfcaef268769f",
            "9f1017edc28b41fda56c7774ed734a5c",
            "92cb586244a746b1a4c1e849a5bfe3de",
            "9c5aa1782c104815b4b7e008c16b19a2",
            "9b423a7a3199432e9f74aa065dacc1c1",
            "b6523c634db0467d8a7c12c54b21a509",
            "44e95ed4f8644977bdbbaca6e04830a9",
            "a3282d7ac15b489aae0f38e63b5e9410",
            "1cf77729c55c416798ed956a402bb8cb",
            "aee88f42eb5548728981a8b0e0babecd",
            "99d189c3d71147fdbc24e120de072dec",
            "a4774ad096f54965a76e429c844b6405",
            "5aa303f44fbf4517877c3db3f65a81c4",
            "f06682b62bfb41fcad588798fed83d2a",
            "e4fc4e4aaea34224ab5fae0515624a04",
            "bcb8faf85c38485895a6abd79446c6fa",
            "dfabbf8928fd43619ea5009e4b1f9469",
            "6bd37601cf7a4e1f95acc4544c71ef39",
            "9a325986b213409e9559029d7ffea0a1",
            "341bd88d699846ae83d1866d16b72789",
            "d961122e8f1440e1a772acf2523f60a8",
            "b117a0068a9741b3bd2f0f2ae10ac607",
            "0c7e9e9c90e0419c8bb4c29466d4dc9c",
            "4d19287757f54f9d8b89d310e4811234",
            "2ddc53610abe4ce9a8eb90f51798bb08",
            "8a385136c880484895efb18a4f132eed",
            "a188e357095b451fb552bb67fc6b688b",
            "b3bb83939b1f4446a822fabe69a9fecd",
            "3cf800e0e354483fa05734d4cc7fb610",
            "76d02fe31b124ce1b0dcb8825fb06039"
          ]
        },
        "outputId": "29009ff4-1ce3-42d9-8e48-732f3f52ebf5"
      },
      "source": [
        "%%time\n",
        "\n",
        "tokenizer = get_tokenier(special_tokens=SPECIAL_TOKENS)\n",
        "model = get_model(tokenizer, \n",
        "                  special_tokens=SPECIAL_TOKENS,\n",
        "                 )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2164d06d725a4850921e999ab673f183",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1713123.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44e95ed4f8644977bdbbaca6e04830a9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1270925.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Special tokens added\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4fc4e4aaea34224ab5fae0515624a04",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=608.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c7e9e9c90e0419c8bb4c29466d4dc9c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=551290714.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 13.6 s, sys: 3.54 s, total: 17.1 s\n",
            "Wall time: 24.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iGa-FRWAzWI"
      },
      "source": [
        "# - Freeze selective layers:\n",
        "# - Freeze all layers except last n:\n",
        "for parameter in model.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "for i, m in enumerate(model.transformer.h):        \n",
        "    #Only un-freeze the last n transformer blocks\n",
        "    if i+1 > 12 - UNFREEZE_LAST_N:\n",
        "        for parameter in m.parameters():\n",
        "            parameter.requires_grad = True \n",
        "\n",
        "for parameter in model.transformer.ln_f.parameters():        \n",
        "    parameter.requires_grad = True\n",
        "\n",
        "for parameter in model.lm_head.parameters():        \n",
        "    parameter.requires_grad = True"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHYTARXZOKwP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "639ee6fd-4cdc-4d0a-cc43-d11b686f366a"
      },
      "source": [
        "train_data, val_data = split_data(data)\n",
        "\n",
        "train_dataset = myDataset(train_data, tokenizer)\n",
        "val_dataset = myDataset(val_data, tokenizer, randomize=False)\n",
        "\n",
        "f'There are {len(train_dataset) :,} samples for training, and {len(val_dataset) :,} samples for validation testing'"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'There are 920 samples for training, and 230 samples for validation testing'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYh9gAM_lAxK"
      },
      "source": [
        "### Fine-tune GPT2 using Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsKQJis8jcCh"
      },
      "source": [
        "%%time\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/\",\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=TRAIN_BATCHSIZE,\n",
        "    per_device_eval_batch_size=TRAIN_BATCHSIZE,\n",
        "    gradient_accumulation_steps=BATCH_UPDATE,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    fp16_opt_level=APEX_OPT_LEVEL,\n",
        "    warmup_steps=WARMUP_STEPS,    \n",
        "    learning_rate=LR,\n",
        "    adam_epsilon=EPS,\n",
        "    weight_decay=0.01,        \n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,     \n",
        ")\n",
        "\n",
        "#---------------------------------------------------#\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,    \n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "#---------------------------------------------------#\n",
        "trainer.train()\n",
        "trainer.save_model()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYvCYf-zfs7V"
      },
      "source": [
        "# Save to G-Drive ----------------------------------#\n",
        "!cp -r 'pytorch_model.bin' '/content/pytorch_model_recipe.bin'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0azvVPXCx4eM"
      },
      "source": [
        "### Сохранение модели для генерации рецепта\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM39_zQLhiZw"
      },
      "source": [
        "# !cp -r '/content/pytorch_model_V2.bin' 'pytorch_model.bin' "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W3m-hnSKf9e"
      },
      "source": [
        "SAVE_DIR = '/content/drive/MyDrive/Colab Notebooks/titles'\n",
        "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'ALCO.pt')\n",
        "torch.save(model.state_dict(),  MODEL_SAVE_PATH )"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rezPx1vGBKY",
        "outputId": "8fe09f46-798c-4ff0-e212-436bc53d2472"
      },
      "source": [
        "model.save_pretrained('/content/sample_data')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/sample_data/config.json\n",
            "Model weights saved in /content/sample_data/pytorch_model.bin\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1erNuYVAJX4"
      },
      "source": [
        "## Генерация рецептов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dojGngEDRupX"
      },
      "source": [
        "tokenizer = get_tokenier(special_tokens=SPECIAL_TOKENS)\n",
        "model = get_model(tokenizer, \n",
        "                  special_tokens=SPECIAL_TOKENS,\n",
        "                  load_model_path='pytorch_model_recipe.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYCC-ugJJy3A"
      },
      "source": [
        "title = \"\"\n",
        "keywords = ['малина','ликер', 'водка', 'пиво', 'вишня']\n",
        "kw = myDataset.join_keywords(keywords, randomize=False)\n",
        "\n",
        "prompt = SPECIAL_TOKENS['bos_token'] + title + \\\n",
        "         SPECIAL_TOKENS['sep_token'] + kw + SPECIAL_TOKENS['sep_token']\n",
        "         \n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "device = torch.device(\"cuda\")\n",
        "generated = generated.to(device)\n",
        "\n",
        "model.eval();"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1gM2DvGeh2i"
      },
      "source": [
        "# Top-p (nucleus) text generation (10 samples):\n",
        "sample_outputs = model.generate(generated, \n",
        "                                do_sample=True,   \n",
        "                                min_length=50, \n",
        "                                max_length=MAXLEN,\n",
        "                                top_k=30,                                 \n",
        "                                top_p=0.7,        \n",
        "                                temperature=0.6,\n",
        "                                repetition_penalty=2.0,\n",
        "                                num_return_sequences=100\n",
        "                                )\n",
        "recipes = []\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "    a = len(title) + len(','.join(keywords))   \n",
        "    recipes.append(\"{}\".format(text[a:])) \n",
        "    print(\"{}\\n\\n\".format(text[a:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6frAvwYBFhGw",
        "outputId": "007c2c17-1639-48e5-b91c-08e109b1ab8c"
      },
      "source": [
        "# Создание словаря с подсчётом слов, которые есть в ввёднных ингредиентах\n",
        "actual_recipe_dict = {}\n",
        "for recipe in recipes:\n",
        "  for i in keywords:\n",
        "    if recipe.find(i.lower()[:-2]) != -1:\n",
        "      if recipe in actual_recipe_dict:\n",
        "        actual_recipe_dict[recipe] += 1\n",
        "      else:\n",
        "        actual_recipe_dict[recipe] = 1\n",
        "\n",
        "actual_recipe_dict\n",
        "sorted_tuple = sorted(actual_recipe_dict.items(), key=lambda x: -x[1])\n",
        "# При условии, что все три ингридиента. А если не три, то топ 3. \n",
        "dict(sorted_tuple)\n",
        "sorted_tuple[0][0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Наполни рокс кубиками льда доверху. Налей ликер мараскино 20 мл и водку 50 г. Долей клюквенный сок 100 дэш в бокал для вина на шпажке'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAmwMuxa3xGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b92830-2e85-47a6-a7e1-f44c209442fa"
      },
      "source": [
        "# Beam-search text generation:\n",
        "sample_outputs = model.generate(generated, \n",
        "                                do_sample=True,   \n",
        "                                max_length=MAXLEN,                                                      \n",
        "                                num_beams=5,\n",
        "                                repetition_penalty=5.0,\n",
        "                                early_stopping=True,      \n",
        "                                num_return_sequences=10\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "    a = len(title) + len(','.join(keywords))    \n",
        "    print(\"{}\\n\\n\".format(text[a:]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Наполни рокс кубиками льда доверху. Положи в шейкер вишневый джем 4 коктейльных ложки и подави мадлером. Налей лимонный сок 15 мл, ликер трипл сек 20 мл и водку 40 мл. Наполни шейкер кубиками льда и взбей. Перелей через стрейнер и ситечко в рокс. Укрась веточкой мяты\n",
            "\n",
            "\n",
            "Наполни рокс кубиками льда доверху. Налей в шейкер лаймовый сок 15 мл, ликер мараскино 20 мл и водку 40 мл. Наполни шейкер кубиками льда и взбей. Перелей через стрейнер в рокс. Укрась апельсиновой цедрой\n",
            "\n",
            "\n",
            "Налей в стопку вишневый ликер 20 мл. Используя коктейльную ложку, уложи слой водки 20 мл\n",
            "\n",
            "\n",
            "Наполни хайбол кубиками льда доверху. Налей в шейкер лаймовый сок 15 мл, ликер мараскино 20 мл и водку 40 мл. Наполни шейкер кубиками льда и взбей. Перелей через стрейнер в хайбол. Укрась кружком лайма\n",
            "\n",
            "\n",
            "Наполни рокс кубиками льда доверху. Положи в шейкер вишневый джем 4 коктейльных ложки и подави мадлером. Налей лимонный сок 15 мл, ликер трипл сек 20 мл и водку 40 мл. Наполни шейкер кубиками льда и взбей. Перелей через стрейнер и ситечко в рокс. Укрась веточкой мяты\n",
            "\n",
            "\n",
            "Наполни рокс кубиками льда доверху. Положи в шейкер вишневый джем 4 коктейльных ложки и подави мадлером. Налей лимонный сок 15 мл, ликер трипл сек 20 мл и водку 40 мл. Наполни шейкер кубиками льда и взбей. Перелей через стрейнер и ситечко в рокс. Укрась веточкой мяты\n",
            "\n",
            "\n",
            "Налей в стопку вишневый ликер 20 мл. Используя коктейльную ложку, уложи слой водки 20 мл\n",
            "\n",
            "\n",
            "Наполни хайбол кубиками льда доверху. Налей в шейкер лаймовый сок 15 мл, ликер мараскино 20 мл и водку 40 мл. Наполни шейкер кубиками льда и взбей. Перелей через стрейнер в хайбол. Долей спрайт доверху и аккуратно размешай коктейльной ложкой\n",
            "\n",
            "\n",
            "Наполни рокс кубиками льда доверху. Налей в шейкер лаймовый сок 15 мл, ликер мараскино 20 мл и водку 40 мл. Наполни шейкер кубиками льда и взбей. Перелей через стрейнер в рокс. Укрась ягодой малины\n",
            "\n",
            "\n",
            "Наполни хайбол кубиками льда доверху. Налей в шейкер лаймовый сок 15 мл, ликер мараскино 20 мл и водку 40 мл. Наполни шейкер кубиками льда и взбей. Перелей через стрейнер в хайбол. Укрась кружком лайма\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX9L43JDPER6"
      },
      "source": [
        "## Создание словаря и обучение модели для генерации названия"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD3mo6xe5095"
      },
      "source": [
        "df_title = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNgmk6ax51Dn"
      },
      "source": [
        "df_title = df_title.reindex(columns=['index', 'recipe', 'name',  'ingridients'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "sgodKw5A51I1",
        "outputId": "cefb4798-49a2-4fca-a355-b77d6f155796"
      },
      "source": [
        "df_title.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>recipe</th>\n",
              "      <th>name</th>\n",
              "      <th>ingridients</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Налей в стакан для смешивания красный вермут 2...</td>\n",
              "      <td>Манхэттен</td>\n",
              "      <td>[бурбон, красный вермут, ангостура биттер, кок...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Наполни слинг кубиками льда доверху. Налей в ш...</td>\n",
              "      <td>Секс на пляже</td>\n",
              "      <td>[водка, персиковый ликер, клюквенный сок, анан...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Налей в шейкер лаймовый сок 10 мл, клюквенный ...</td>\n",
              "      <td>Космополитен</td>\n",
              "      <td>[цитрусовая водка, трипл сек, клюквенный сок, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Налей в стопку кофейный ликер 15 мл. Используя...</td>\n",
              "      <td>Б-52</td>\n",
              "      <td>[кофейный ликер, айриш крим, трипл сек]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Наполни харрикейн кубиками льда доверху. Налей...</td>\n",
              "      <td>Голубая лагуна</td>\n",
              "      <td>[водка, ликер блю кюрасао, спрайт, ананас, лед...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Сделай на бокале для маргариты соленую окаемку...</td>\n",
              "      <td>Маргарита</td>\n",
              "      <td>[серебряная текила, трипл сек, сахарный сироп,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Наполни бокал для вина льдом. Налей в бокал пр...</td>\n",
              "      <td>Апероль Шприц</td>\n",
              "      <td>[апероль, просекко, содовая, апельсин, лед в к...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Наполни френчпресс кубиками льда доверху. Нале...</td>\n",
              "      <td>Лонг айленд айс ти</td>\n",
              "      <td>[лондонский сухой джин, водка, белый ром, сере...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Наполни рокс кубиками льда доверху. Налей в ше...</td>\n",
              "      <td>Роза Багси</td>\n",
              "      <td>[водка, сироп розы, лаймовый кордиал, лаймовый...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Налей в стопку водку 50 мл. Налей в другую сто...</td>\n",
              "      <td>Малевич шутер</td>\n",
              "      <td>[водка, соленый огурец, мед]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                        ingridients\n",
              "0      0  ...  [бурбон, красный вермут, ангостура биттер, кок...\n",
              "1      1  ...  [водка, персиковый ликер, клюквенный сок, анан...\n",
              "2      2  ...  [цитрусовая водка, трипл сек, клюквенный сок, ...\n",
              "3      3  ...            [кофейный ликер, айриш крим, трипл сек]\n",
              "4      4  ...  [водка, ликер блю кюрасао, спрайт, ананас, лед...\n",
              "5      5  ...  [серебряная текила, трипл сек, сахарный сироп,...\n",
              "6      6  ...  [апероль, просекко, содовая, апельсин, лед в к...\n",
              "7      7  ...  [лондонский сухой джин, водка, белый ром, сере...\n",
              "8      8  ...  [водка, сироп розы, лаймовый кордиал, лаймовый...\n",
              "9      9  ...                       [водка, соленый огурец, мед]\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD9hr2SY51RE"
      },
      "source": [
        "data_title = df_title.set_index('index').T.to_dict('list')\n",
        "data_title"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkSnmSoL51Wi",
        "outputId": "07f4ef8b-5459-4ebf-865a-9fc917f613bc"
      },
      "source": [
        "%%time\n",
        "\n",
        "tokenizer_title = get_tokenier(special_tokens=SPECIAL_TOKENS)\n",
        "model_title = get_model(tokenizer_title, \n",
        "                  special_tokens=SPECIAL_TOKENS,\n",
        "                 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/1b36eeb1fd7b3a6ec11bf46bde2c38e7e68f71ec774694b9e886c86001aab35d.c483bc3440d25937fdac74506b73b76ee6e67f778a804756214363fc2a1a66ef\n",
            "loading file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/479aa59074c4dcd4c36106252da033d03bc92e3010947ce1d3714de224c2af1f.7362c0dbb32f750eeea5a5b93bbd0c6876eac41453369265d5a49df1c9142b6f\n",
            "loading file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/tokenizer.json from cache at None\n",
            "Assigning <|BOS|> to the bos_token key of the tokenizer\n",
            "Adding <|BOS|> to the vocabulary\n",
            "Assigning <|EOS|> to the eos_token key of the tokenizer\n",
            "Adding <|EOS|> to the vocabulary\n",
            "Assigning <|UNK|> to the unk_token key of the tokenizer\n",
            "Assigning <|PAD|> to the pad_token key of the tokenizer\n",
            "Adding <|PAD|> to the vocabulary\n",
            "Assigning <|SEP|> to the sep_token key of the tokenizer\n",
            "Adding <|SEP|> to the vocabulary\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Special tokens added\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/06f48b6b3173390d047e15d691fda67ae4ea7733a5eea4b6e0115f5099c4e700.b5cdfa39c63384f94159c36bc9042660c747cea5cf520b43d543bd2c68b3164d\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50257,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50258,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 2048,\n",
            "  \"pad_token_id\": 50259,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"sep_token_id\": 50260,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/df2b64a4c86a349ba84354d85b7117b106f2b87085c9bb54cde70d3751907c45.4e3da19dd8adaa6d6a9804bfd45d2dcf17ba544de445847443ef1816bfa3d693\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at sberbank-ai/rugpt3small_based_on_gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.61 s, sys: 317 ms, total: 2.93 s\n",
            "Wall time: 8.54 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mdhgtSqDL0Bv",
        "outputId": "c85c86bc-02c0-4b72-be7f-39d8beb95b4a"
      },
      "source": [
        "train_data_title, val_data_title = split_data(data_title)\n",
        "\n",
        "train_dataset_title = myDataset(train_data_title, tokenizer_title)\n",
        "val_dataset_title = myDataset(val_data_title, tokenizer_title, randomize=False)\n",
        "\n",
        "f'There are {len(train_dataset_title) :,} samples for training, and {len(val_dataset_title) :,} samples for validation testing'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'There are 920 samples for training, and 230 samples for validation testing'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hoUQrGhUL0G_",
        "outputId": "abee9168-6874-4a00-de11-0664f68923d6"
      },
      "source": [
        "%%time\n",
        "\n",
        "training_args_title = TrainingArguments(\n",
        "    output_dir=\"/content/\",\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=TRAIN_BATCHSIZE,\n",
        "    per_device_eval_batch_size=TRAIN_BATCHSIZE,\n",
        "    gradient_accumulation_steps=BATCH_UPDATE,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    fp16_opt_level=APEX_OPT_LEVEL,\n",
        "    warmup_steps=WARMUP_STEPS,    \n",
        "    learning_rate=LR,\n",
        "    adam_epsilon=EPS,\n",
        "    weight_decay=0.01,        \n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,     \n",
        ")\n",
        "\n",
        "#---------------------------------------------------#\n",
        "trainer_title = Trainer(\n",
        "    model=model_title,\n",
        "    args=training_args_title,    \n",
        "    train_dataset=train_dataset_title,\n",
        "    eval_dataset=val_dataset_title,\n",
        "    tokenizer=tokenizer_title\n",
        ")\n",
        "\n",
        "#---------------------------------------------------#\n",
        "trainer_title.train()\n",
        "trainer_title.save_model()    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "Using amp fp16 backend\n",
            "***** Running training *****\n",
            "  Num examples = 920\n",
            "  Num Epochs = 15\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 96\n",
            "  Gradient Accumulation steps = 24\n",
            "  Total optimization steps = 135\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='136' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [135/135 35:11, Epoch 14.94/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>9.439652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.406001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.415639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.269523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.208465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.177891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.167347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.159580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.159949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.158882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.158676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.157382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.158656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.160512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.160172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-9\n",
            "Configuration saved in /content/checkpoint-9/config.json\n",
            "Model weights saved in /content/checkpoint-9/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-9/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-9/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-9/added_tokens.json\n",
            "Deleting older checkpoint [/content/checkpoint-135] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-18\n",
            "Configuration saved in /content/checkpoint-18/config.json\n",
            "Model weights saved in /content/checkpoint-18/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-18/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-18/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-18/added_tokens.json\n",
            "Deleting older checkpoint [/content/checkpoint-9] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-27\n",
            "Configuration saved in /content/checkpoint-27/config.json\n",
            "Model weights saved in /content/checkpoint-27/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-27/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-27/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-27/added_tokens.json\n",
            "Deleting older checkpoint [/content/checkpoint-18] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-36\n",
            "Configuration saved in /content/checkpoint-36/config.json\n",
            "Model weights saved in /content/checkpoint-36/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-36/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-36/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-36/added_tokens.json\n",
            "Deleting older checkpoint [/content/checkpoint-27] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-45\n",
            "Configuration saved in /content/checkpoint-45/config.json\n",
            "Model weights saved in /content/checkpoint-45/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-45/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-45/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-45/added_tokens.json\n",
            "Deleting older checkpoint [/content/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-54\n",
            "Configuration saved in /content/checkpoint-54/config.json\n",
            "Model weights saved in /content/checkpoint-54/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-54/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-54/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-54/added_tokens.json\n",
            "Deleting older checkpoint [/content/checkpoint-45] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-63\n",
            "Configuration saved in /content/checkpoint-63/config.json\n",
            "Model weights saved in /content/checkpoint-63/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-63/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-63/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-63/added_tokens.json\n",
            "Deleting older checkpoint [/content/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-72\n",
            "Configuration saved in /content/checkpoint-72/config.json\n",
            "Model weights saved in /content/checkpoint-72/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-72/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-72/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-72/added_tokens.json\n",
            "Deleting older checkpoint [/content/checkpoint-63] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-81\n",
            "Configuration saved in /content/checkpoint-81/config.json\n",
            "Model weights saved in /content/checkpoint-81/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-81/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-81/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-81/added_tokens.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-90\n",
            "Configuration saved in /content/checkpoint-90/config.json\n",
            "Model weights saved in /content/checkpoint-90/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-90/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-90/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-90/added_tokens.json\n",
            "Deleting older checkpoint [/content/checkpoint-72] due to args.save_total_limit\n",
            "Deleting older checkpoint [/content/checkpoint-81] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-99\n",
            "Configuration saved in /content/checkpoint-99/config.json\n",
            "Model weights saved in /content/checkpoint-99/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-99/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-99/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-99/added_tokens.json\n",
            "Deleting older checkpoint [/content/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-108\n",
            "Configuration saved in /content/checkpoint-108/config.json\n",
            "Model weights saved in /content/checkpoint-108/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-108/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-108/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-108/added_tokens.json\n",
            "Deleting older checkpoint [/content/checkpoint-99] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-117\n",
            "Configuration saved in /content/checkpoint-117/config.json\n",
            "Model weights saved in /content/checkpoint-117/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-117/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-117/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-117/added_tokens.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-126\n",
            "Configuration saved in /content/checkpoint-126/config.json\n",
            "Model weights saved in /content/checkpoint-126/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-126/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-126/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-126/added_tokens.json\n",
            "Deleting older checkpoint [/content/checkpoint-117] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 230\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to /content/checkpoint-135\n",
            "Configuration saved in /content/checkpoint-135/config.json\n",
            "Model weights saved in /content/checkpoint-135/pytorch_model.bin\n",
            "tokenizer config file saved in /content/checkpoint-135/tokenizer_config.json\n",
            "Special tokens file saved in /content/checkpoint-135/special_tokens_map.json\n",
            "added tokens file saved in /content/checkpoint-135/added_tokens.json\n",
            "Deleting older checkpoint [/content/checkpoint-126] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/checkpoint-108 (score: 0.15738242864608765).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [135/135 35:35, Epoch 14/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>9.439652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.406001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.415639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.269523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.208465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.177891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.167347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.159580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.159949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.158882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.158676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.157382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.158656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.160512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.160172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to /content/\n",
            "Configuration saved in /content/config.json\n",
            "Model weights saved in /content/pytorch_model.bin\n",
            "tokenizer config file saved in /content/tokenizer_config.json\n",
            "Special tokens file saved in /content/special_tokens_map.json\n",
            "added tokens file saved in /content/added_tokens.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 31min 2s, sys: 4min 11s, total: 35min 14s\n",
            "Wall time: 35min 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNFMyaTmL0Mp"
      },
      "source": [
        "SAVE_DIR = '/content/'\n",
        "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'ALCO_title.pt')\n",
        "torch.save(model_title.state_dict(),  MODEL_SAVE_PATH )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrjlUj-hL0SZ"
      },
      "source": [
        "# title = \"\"\n",
        "# recipe = \"Наполни хайбол кубиками льда доверху. Налей клубничный сироп 30 мл и ревеневый ликер 5 мл. Добавь односолодовый виски из Хайленда 30 мл. Долей содовую доверху и аккуратно размешай коктейльной ложкой. Укрась одной крупно нарезанной клубникой\"\n",
        "kw = myDataset.join_keywords(keywords, randomize=False)\n",
        "recipe = sorted_tuple[0][0]\n",
        "\n",
        "prompt = SPECIAL_TOKENS['bos_token'] + recipe + \\\n",
        "         SPECIAL_TOKENS['sep_token'] + kw + SPECIAL_TOKENS['sep_token']\n",
        "         \n",
        "generated_title = torch.tensor(tokenizer_title.encode(prompt)).unsqueeze(0)\n",
        "device = torch.device(\"cuda\")\n",
        "generated_title = generated_title.to(device)\n",
        "\n",
        "model_title.eval();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI9mF4AkL0Yf"
      },
      "source": [
        "# Top-p (nucleus) text generation (10 samples):\n",
        "sample_outputs_title = model_title.generate(generated_title, \n",
        "                                do_sample=True,   \n",
        "                                min_length=50, \n",
        "                                max_length=MAXLEN,\n",
        "                                top_k=30,                                 \n",
        "                                top_p=0.7,        \n",
        "                                temperature=0.93,\n",
        "                                repetition_penalty=2.0,\n",
        "                                num_return_sequences=100\n",
        "                                )\n",
        "titles = []\n",
        "for i, sample_output in enumerate(sample_outputs_title):\n",
        "    text = tokenizer_title.decode(sample_output, skip_special_tokens=True)\n",
        "    a = len(recipe) + len(','.join(keywords))   \n",
        "    titles.append(\"{}\".format(text[a:])) \n",
        "    print(\"{}\\n\\n\".format(text[a:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SZw5rrXL0dt"
      },
      "source": [
        "set_title = set(titles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58wmwEMCL0ns",
        "outputId": "bcdb6db5-001f-486b-995a-600222ce30e0"
      },
      "source": [
        "import random\n",
        "\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['44: Водяная зараза']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTMDxJflL0to"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJCjAihHL0x8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mMzddc6L02B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcEftaCzL06I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ1w2JK5L0-z"
      },
      "source": [
        "##Выдача результатов готовых рецептов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP7phWV0L1Fj"
      },
      "source": [
        "df_result = df.copy()\n",
        "df_result.ingridients = df_result.ingridients.apply(', '.join)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVwERpFQCSPQ"
      },
      "source": [
        "df_result.to_csv('ready_recipe.csv')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "M8_yA6Y9CkQD",
        "outputId": "d1f793fa-bd51-4227-9d94-13bf1707770d"
      },
      "source": [
        "df_result = pd.read_csv('ready_recipe.csv')\n",
        "df_result.drop('Unnamed: 0', axis = 1, inplace=True)\n",
        "df_result"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>name</th>\n",
              "      <th>recipe</th>\n",
              "      <th>ingridients</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Манхэттен</td>\n",
              "      <td>Налей в стакан для смешивания красный вермут 2...</td>\n",
              "      <td>бурбон, красный вермут, ангостура биттер, кокт...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Секс на пляже</td>\n",
              "      <td>Наполни слинг кубиками льда доверху. Налей в ш...</td>\n",
              "      <td>водка, персиковый ликер, клюквенный сок, анана...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Космополитен</td>\n",
              "      <td>Налей в шейкер лаймовый сок 10 мл, клюквенный ...</td>\n",
              "      <td>цитрусовая водка, трипл сек, клюквенный сок, л...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Б-52</td>\n",
              "      <td>Налей в стопку кофейный ликер 15 мл. Используя...</td>\n",
              "      <td>кофейный ликер, айриш крим, трипл сек</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Голубая лагуна</td>\n",
              "      <td>Наполни харрикейн кубиками льда доверху. Налей...</td>\n",
              "      <td>водка, ликер блю кюрасао, спрайт, ананас, лед ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1145</th>\n",
              "      <td>1145</td>\n",
              "      <td>Карибский бриз</td>\n",
              "      <td>Наполни хайбол кубиками льда доверху. Налей гр...</td>\n",
              "      <td>грейпфрутовая водка, домашняя ванильная водка,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1146</th>\n",
              "      <td>1146</td>\n",
              "      <td>Текила санрайз</td>\n",
              "      <td>Наполни хайбол кубиками льда доверху. Налей гр...</td>\n",
              "      <td>серебряная текила, гренадин, апельсиновый сок,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1147</th>\n",
              "      <td>1147</td>\n",
              "      <td>Мохито</td>\n",
              "      <td>Положи в хайбол лайм 3 дольки и подави мадлеро...</td>\n",
              "      <td>белый ром, сахарный сироп, содовая, лайм, мята...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1148</th>\n",
              "      <td>1148</td>\n",
              "      <td>Белый русский</td>\n",
              "      <td>Наполни рокс кубиками льда доверху. Налей в бо...</td>\n",
              "      <td>водка, кофейный ликер, нежирные сливки, лед в ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1149</th>\n",
              "      <td>1149</td>\n",
              "      <td>Негрони</td>\n",
              "      <td>Наполни рокс кубиками льда доверху. Налей в бо...</td>\n",
              "      <td>лондонский сухой джин, красный вермут, красный...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1150 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ...                                        ingridients\n",
              "0         0  ...  бурбон, красный вермут, ангостура биттер, кокт...\n",
              "1         1  ...  водка, персиковый ликер, клюквенный сок, анана...\n",
              "2         2  ...  цитрусовая водка, трипл сек, клюквенный сок, л...\n",
              "3         3  ...              кофейный ликер, айриш крим, трипл сек\n",
              "4         4  ...  водка, ликер блю кюрасао, спрайт, ананас, лед ...\n",
              "...     ...  ...                                                ...\n",
              "1145   1145  ...  грейпфрутовая водка, домашняя ванильная водка,...\n",
              "1146   1146  ...  серебряная текила, гренадин, апельсиновый сок,...\n",
              "1147   1147  ...  белый ром, сахарный сироп, содовая, лайм, мята...\n",
              "1148   1148  ...  водка, кофейный ликер, нежирные сливки, лед в ...\n",
              "1149   1149  ...  лондонский сухой джин, красный вермут, красный...\n",
              "\n",
              "[1150 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN_7OmX051gU",
        "outputId": "9b881c82-f5ee-4973-a102-636c351f0e76"
      },
      "source": [
        "%%time\n",
        "ready_recipe_dict = {}\n",
        "\n",
        "for index, row in df_result.iterrows():\n",
        "  for keyword in keywords:\n",
        "    if row.ingridients.find(keyword) != -1:\n",
        "      if index in ready_recipe_dict:\n",
        "        ready_recipe_dict[index] += 1\n",
        "      else:\n",
        "        ready_recipe_dict[index] = 1\n",
        "\n",
        "max_ready_dict = max(ready_recipe_dict.values())\n",
        "\n",
        "for k, v in ready_recipe_dict.items():\n",
        "        if v == max_ready_dict:\n",
        "          print(f'{df_result[\"name\"][k]} : {df_result[\"recipe\"][k]}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Секс на пляже : Наполни слинг кубиками льда доверху. Налей в шейкер клюквенный сок 40 мл, ананасовый сок 40 мл, персиковый ликер 25 мл и водку 50 мл. Наполни шейкер кубиками льда и взбей. Перелей через стрейнер в слинг. Укрась кусочком ананаса и ягодой малины на коктейльной шпажке\n",
            "Морс мартини : Положи в шейкер клубнику 2 ягоды, малину 2 ягоды, чернику 1 коктейльную ложку и подави мадлером. Налей клюквенный сок 30 мл, сахарный сироп 10 мл, черносмородиновый ликер 10 мл и водку 30 мл. Наполни шейкер кубиками льда и взбей. Перелей через стрейнер и ситечко в охлажденный коктейльный бокал. Укрась веточкой красной смородины\n",
            "Белый и перечный : Наполни слинг кубиками льда доверху. Положи в шейкер пюре личи 12 коктейльных ложек. Налей белок перепелиного яйца, лимонный сок 30 мл, сахарный сироп 10 мл, ликер личи 20 мл и водку 40 мл. Наполни шейкер кубиками льда и тщательно взбей. Перелей через стрейнер в слинг. Укрась очищенным личи, малинкой и щепоткой черного молотого перца\n",
            "Блинк-блинк : Налей в шейкер лаймовый сок 10 мл, малиновый ликер 10 мл и водку 10 мл. Наполни шейкер кубиками льда и взбей. Перелей через стрейнер в стопку. Долей просекко доверху. Укрась малинкой на шпажке. Выпей шот и заверши его малиной\n",
            "Наоми : Положи в шейкер ежевику 3 ягоды, малину 3 ягоды и подави мадлером. Налей кофейный ликер 20 мл и черносмородиновую водку 40 мл. Наполни шейкер кубиками льда и взбей. Перелей через стрейнер и ситечко в охлажденный коктейльный бокал. Налей в миску жирные сливки 50 мл и ванильный сироп 5 мл. Тщательно взбей венчиком. Используя коктейльную ложку, уложи на коктейль слой ванильных сливок из миски. Укрась ежевикой на коктейльной шпажке. Если ты хочешь приготовить много коктейлей и будешь использовать более 500 мл сливок, удобнее воспользоваться сифоном для сливок\n",
            "CPU times: user 98.8 ms, sys: 32 µs, total: 98.8 ms\n",
            "Wall time: 101 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfQte8N4fsNu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN5CLPJYFXFT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4UjMTwWx-ky"
      },
      "source": [
        "### Generating text with raw GPT2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbiaQldb1RPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122b64ac-48fa-4d60-8802-819b9b74d640"
      },
      "source": [
        "tokenizer_raw = get_tokenier()\n",
        "model_raw = get_model(tokenizer_raw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/1b36eeb1fd7b3a6ec11bf46bde2c38e7e68f71ec774694b9e886c86001aab35d.c483bc3440d25937fdac74506b73b76ee6e67f778a804756214363fc2a1a66ef\n",
            "loading file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/479aa59074c4dcd4c36106252da033d03bc92e3010947ce1d3714de224c2af1f.7362c0dbb32f750eeea5a5b93bbd0c6876eac41453369265d5a49df1c9142b6f\n",
            "loading file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/tokenizer.json from cache at None\n",
            "loading configuration file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/06f48b6b3173390d047e15d691fda67ae4ea7733a5eea4b6e0115f5099c4e700.b5cdfa39c63384f94159c36bc9042660c747cea5cf520b43d543bd2c68b3164d\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 2048,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50264\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/sberbank-ai/rugpt3small_based_on_gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/df2b64a4c86a349ba84354d85b7117b106f2b87085c9bb54cde70d3751907c45.4e3da19dd8adaa6d6a9804bfd45d2dcf17ba544de445847443ef1816bfa3d693\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at sberbank-ai/rugpt3small_based_on_gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1ag9Z0iZbzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb54d5a-e044-46b4-ac3e-52058522a4af"
      },
      "source": [
        "prompt = 'Наше прошлое скакало по окну'\n",
        "\n",
        "generated = torch.tensor(tokenizer_raw.encode(prompt)).unsqueeze(0)\n",
        "device = torch.device(\"cuda\")\n",
        "generated = generated.to(device)\n",
        "\n",
        "model_raw.eval()\n",
        "sample_outputs = model_raw.generate(generated, \n",
        "                                do_sample=True,   \n",
        "                                max_length=MAXLEN,                                                      \n",
        "                                num_beams=5,\n",
        "                                repetition_penalty=5.0,\n",
        "                                early_stopping=True,      \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    print(\"{}: {}\\n\\n\".format(i, tokenizer_raw.decode(sample_output, skip_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0: Наше прошлое скакало по окну,\n",
            "\t\tА наше будущее прыгало в окно.\n",
            "\t\tМы мечтали о том, что будет когда-нибудь,\n",
            "\t\tНо все это было не так уж и важно.\n",
            "\t\tИ вот наступил тот день, когда мы поняли,\n",
            "\t\tЧто нам никогда не суждено быть вместе.\n",
            "\t\tВ этот день я понял, что мне ничего не светит,\n",
            "\t\tЯ знал, что у меня нет будущего,\n",
            "\t\tОно осталось где-то там, за горизонтом.\n",
            "\t\tМне казалось, что сейчас наступит конец света,\n",
            "\t\tВедь с тех пор прошло уже много лет,\n",
            "\t\tС тех пор как умерла моя мама…\n",
            "\t\tВсе эти годы я думал только об одном:\n",
            "\t\tКак бы поскорее избавиться от этого кошмара.\n",
            "\t\tЗабыть обо всем на свете!\n",
            "\t\tУйти из этой жизни навсегда!\n",
            "\t\tОтказаться от всех земных радостей!\n",
            "\t\tВернуться к нормальной жизни!\n",
            "\t\tПосмотреть на мир другими глазами!\n",
            "\t\tНе думать ни о чем плохом!\n",
            "\t\tПожелать друг другу всего самого лучшего!\n",
            "\t\tБыть счастливыми вечно!\n",
            "\t\tЖить полной жизнью!\n",
            "\t\tДа здравствует любовь!\n",
            "\t\tБудьте счастливы всегда!\n",
            "\t\tПусть каждый день приносит вам лишь радость!\n",
            "\t\tПоздравляю вас с наступающим Новым годом!\n",
            "\t\tДо новых встреч!\n",
            "\n",
            "    1977 г.\n",
            "\n",
            "\n",
            "\n",
            "«Зимняя сказка…»\n",
            "\n",
            "\n",
            "\t\tЗимняя сказка\n",
            "\t\tЛетит снежок пушистый,\n",
            "\t\tШепчет песенка веселая,\n",
            "\t\tВетер колышет елочки,\n",
            "\t\tЧудесный хоровод кружит,\n",
            "\t\tВолшебные слова поют,\n",
            "\t\tВеселятся детишки,\n",
            "\t\tХвалят Дед Мороз и Снегурочка,\n",
            "\t\tДед Мороз со Снегурочкой поздравляют,\n",
            "\t\tДевочки звонко щебечут,\n",
            "\t\tМороз трещит вовсю,\n",
            "\t\tЛетают снежинки во все стороны,\n",
            "\t\tГоры блестят разноцветными огнями,\n",
            "\t\tБелоснежные домики горят,\n",
            "\t\tКрасота кругом!\n",
            "\t\tВот он – Новый год!\n",
            "\t\tНовый год стучится в двери,\n",
            "\t\tНовогодний стол накрыт,\n",
            "\t\tРаздаются веселые голоса,\n",
            "\t\tРождественская елка сияет,\n",
            "\t\tКружится веселый хоровод,\n",
            "\t\tДетишки катаются на санках,\n",
            "\t\tПодарки для Деда Мороза дарят,\n",
            "\t\tПриятно пахнет мандаринами,\n",
            "\t\tЗамечательные подарки вручают,\n",
            "\t\tМасленицу справляют,\n",
            "\t\tЦветочки украшают,\n",
            "\t\tМалинки угощают,\n",
            "\t\tГусят запекают,\n",
            "\t\tКукушек кормят,\n",
            "\t\tЕлка наряжается,\n",
            "\t\tКолокольчики звенят,\n",
            "\t\tСтруны гитары пляшут,\n",
            "\t\tТанец живота танцует,\n",
            "\t\tГолубые огоньки мерцают,\n",
            "\t\tКрасавиц балуют,\n",
            "\t\tМузыканты песни поют,\n",
            "\t\tДетей развлекают,\n",
            "\t\tСамолеты летают,\n",
            "\t\tПесни распевают,\n",
            "\t\tКартинки рисуют,\n",
            "\t\tФонарики зажигают,\n",
            "\t\tПо улицам гуляют,\n",
            "\t\tВстречают Новый год,\n",
            "\t\t\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ9CS9UsVsl5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}